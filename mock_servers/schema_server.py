import json
import random
from typing import Dict, Any, List, Optional
from fastapi import HTTPException

from .base_server import MockServer
from ..data_generation.api_schema_generator import APISchemaGenerator
from ..data_generation.endpoint_generator import EndpointSpec


class SchemaBasedMockServer(MockServer):
    """
    Extended mock server that can dynamically create endpoints
    from API schemas generated by APISchemaGenerator.
    """
    
    def __init__(
        self,
        schema_generator: Optional[APISchemaGenerator] = None,
        **kwargs
    ):
        super().__init__(**kwargs)
        self.schema_generator = schema_generator or APISchemaGenerator()
        self.current_schema: Optional[Dict[str, Any]] = None
        self.schema_scenarios: List[Dict[str, Any]] = []
    
    def load_from_openapi_spec(self, openapi_spec: Dict[str, Any]) -> None:
        """Load endpoints from an OpenAPI specification"""
        try:
            self.current_schema = openapi_spec
            
            # Extract endpoint specifications from OpenAPI spec
            endpoints = self._extract_endpoints_from_openapi(openapi_spec)
            
            # Register all endpoints
            self.register_endpoints(endpoints)
            
            self.logger.info(f"Loaded {len(endpoints)} endpoints from OpenAPI spec")
            
        except Exception as e:
            self.logger.error(f"Failed to load OpenAPI spec: {str(e)}")
            raise Exception(f"Failed to load OpenAPI spec: {str(e)}")
    
    def load_from_scenario(self, scenario: Dict[str, Any]) -> None:
        """Load endpoints from a training scenario"""
        try:
            endpoints = []
            
            for endpoint_data in scenario.get("endpoints", []):
                spec_dict = endpoint_data.get("specification", {})
                
                # Convert specification dict back to EndpointSpec
                endpoint_spec = self._dict_to_endpoint_spec(spec_dict)
                endpoints.append(endpoint_spec)
                
                # Store sample data for this endpoint if available
                sample_responses = endpoint_data.get("sample_responses", [])
                if sample_responses:
                    self._register_sample_responses(endpoint_spec, sample_responses)
            
            # Register all endpoints
            self.register_endpoints(endpoints)
            
            self.logger.info(f"Loaded {len(endpoints)} endpoints from scenario: {scenario.get('name', 'Unknown')}")
            
        except Exception as e:
            self.logger.error(f"Failed to load scenario: {str(e)}")
            raise Exception(f"Failed to load scenario: {str(e)}")
    
    def generate_and_load_random_api(
        self,
        title: str = "Random Mock API",
        num_endpoints: int = 5,
        endpoint_tags: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """Generate a random API specification and load it"""
        try:
            if endpoint_tags:
                openapi_spec = self.schema_generator.generate_openapi_spec(
                    title=title,
                    include_endpoints=endpoint_tags
                )
            else:
                openapi_spec = self.schema_generator.generate_openapi_spec(
                    title=title,
                    endpoint_count=num_endpoints
                )
            
            # Update server info
            self.title = openapi_spec["info"]["title"]
            self.description = openapi_spec["info"]["description"]
            self.version = openapi_spec["info"]["version"]
            
            # Load the generated spec
            self.load_from_openapi_spec(openapi_spec)
            
            self.logger.info(f"Generated and loaded random API: {title}")
            return openapi_spec
            
        except Exception as e:
            self.logger.error(f"Failed to generate random API: {str(e)}")
            raise Exception(f"Failed to generate random API: {str(e)}")
    
    def load_user_management_api(self) -> Dict[str, Any]:
        """Load a complete user management API"""
        spec = self.schema_generator.generate_user_management_spec()
        self.load_from_openapi_spec(spec)
        return spec
    
    def load_product_catalog_api(self) -> Dict[str, Any]:
        """Load a complete product catalog API"""
        spec = self.schema_generator.generate_product_catalog_spec()
        self.load_from_openapi_spec(spec)
        return spec
    
    def load_training_dataset(self, dataset: List[Dict[str, Any]]) -> None:
        """Load multiple scenarios from a training dataset"""
        self.schema_scenarios = dataset
        
        # Load the first scenario by default
        if dataset:
            self.load_from_scenario(dataset[0])
            self.logger.info(f"Loaded training dataset with {len(dataset)} scenarios")
    
    def switch_to_scenario(self, scenario_index: int) -> None:
        """Switch to a different scenario from the loaded dataset"""
        if not self.schema_scenarios:
            raise Exception("No training dataset loaded")
        
        if scenario_index < 0 or scenario_index >= len(self.schema_scenarios):
            raise Exception(f"Invalid scenario index: {scenario_index}")
        
        # Clear current endpoints
        if not self.is_running:
            self.clear_endpoints()
        else:
            raise Exception("Cannot switch scenarios while server is running")
        
        # Load new scenario
        scenario = self.schema_scenarios[scenario_index]
        self.load_from_scenario(scenario)
        
        self.logger.info(f"Switched to scenario {scenario_index}: {scenario.get('name', 'Unknown')}")
    
    def _extract_endpoints_from_openapi(self, openapi_spec: Dict[str, Any]) -> List[EndpointSpec]:
        """Extract EndpointSpec objects from OpenAPI specification"""
        endpoints = []
        paths = openapi_spec.get("paths", {})
        
        for path, methods in paths.items():
            for method, spec in methods.items():
                if method.upper() in ["GET", "POST", "PUT", "DELETE"]:
                    try:
                        endpoint_spec = EndpointSpec(
                            path=path,
                            method=getattr(__import__("..data_generation.endpoint_generator", fromlist=["HTTPMethod"]).HTTPMethod, method.upper()),
                            summary=spec.get("summary", f"{method.upper()} {path}"),
                            description=spec.get("description", ""),
                            parameters=spec.get("parameters", []),
                            request_body=spec.get("requestBody"),
                            responses=spec.get("responses", {}),
                            tags=spec.get("tags", [])
                        )
                        endpoints.append(endpoint_spec)
                    except Exception as e:
                        self.logger.warning(f"Skipping endpoint {method.upper()} {path}: {str(e)}")
        
        return endpoints
    
    def _dict_to_endpoint_spec(self, spec_dict: Dict[str, Any]) -> EndpointSpec:
        """Convert a specification dictionary back to EndpointSpec"""
        from ..data_generation.endpoint_generator import HTTPMethod
        
        return EndpointSpec(
            path=spec_dict["path"],
            method=HTTPMethod(spec_dict["method"]),
            summary=spec_dict["summary"],
            description=spec_dict["description"],
            parameters=spec_dict.get("parameters", []),
            request_body=spec_dict.get("requestBody"),
            responses=spec_dict.get("responses", {}),
            tags=spec_dict.get("tags", [])
        )
    
    def _register_sample_responses(self, endpoint_spec: EndpointSpec, sample_responses: List[Dict[str, Any]]) -> None:
        """Register custom handlers that return sample responses"""
        handler_key = f"{endpoint_spec.method.value}:{endpoint_spec.path}"
        
        async def sample_handler(request, **path_params):
            # Select a random sample response
            sample = random.choice(sample_responses)
            status_code = sample.get("status_code", 200)
            data = sample.get("data", {})
            
            from fastapi.responses import JSONResponse
            return JSONResponse(content=data, status_code=status_code)
        
        self.add_custom_handler(endpoint_spec.method.value, endpoint_spec.path, sample_handler)
    
    def get_current_schema_info(self) -> Dict[str, Any]:
        """Get information about the currently loaded schema"""
        return {
            "title": self.title,
            "description": self.description,
            "version": self.version,
            "endpoints_count": len(self.registered_endpoints),
            "scenarios_available": len(self.schema_scenarios),
            "has_current_schema": self.current_schema is not None,
            "endpoints": [
                {
                    "path": ep.path,
                    "method": ep.method.value,
                    "summary": ep.summary,
                    "tags": ep.tags
                }
                for ep in self.registered_endpoints
            ]
        }
    
    def export_current_schema(self, filename: str) -> None:
        """Export the currently loaded schema to a file"""
        if not self.current_schema:
            raise Exception("No schema currently loaded")
        
        with open(filename, 'w') as f:
            json.dump(self.current_schema, f, indent=2, default=str)
        
        self.logger.info(f"Exported current schema to {filename}")
    
    def add_realistic_delay(self, min_ms: int = 50, max_ms: int = 500) -> None:
        """Add realistic response delays to all endpoints"""
        import asyncio
        
        original_handlers = self.custom_handlers.copy()
        
        for endpoint in self.registered_endpoints:
            handler_key = f"{endpoint.method.value}:{endpoint.path}"
            original_handler = original_handlers.get(handler_key)
            
            async def delayed_handler(request, **path_params):
                # Add realistic delay
                delay = random.uniform(min_ms, max_ms) / 1000.0
                await asyncio.sleep(delay)
                
                if original_handler:
                    return await original_handler(request, **path_params)
                else:
                    # Use default response generation
                    response_data = self.data_generator.generate_api_response_data(
                        endpoint.path, endpoint.method.value, status_code=200
                    )
                    status_code = 204 if endpoint.method.value == "DELETE" else (201 if endpoint.method.value == "POST" else 200)
                    
                    from fastapi.responses import JSONResponse
                    return JSONResponse(content=response_data, status_code=status_code)
            
            self.add_custom_handler(endpoint.method.value, endpoint.path, delayed_handler)
        
        self.logger.info(f"Added realistic delays ({min_ms}-{max_ms}ms) to all endpoints")
    
    def simulate_error_responses(self, error_rate: float = 0.1) -> None:
        """Add random error responses to simulate real API behavior"""
        import asyncio
        
        original_handlers = self.custom_handlers.copy()
        
        for endpoint in self.registered_endpoints:
            handler_key = f"{endpoint.method.value}:{endpoint.path}"
            original_handler = original_handlers.get(handler_key)
            
            async def error_prone_handler(request, **path_params):
                # Randomly return error responses
                if random.random() < error_rate:
                    error_codes = [400, 401, 403, 404, 422, 500]
                    error_code = random.choice(error_codes)
                    error_data = self.data_generator.generate_error_response(error_code)
                    
                    from fastapi.responses import JSONResponse
                    return JSONResponse(content=error_data, status_code=error_code)
                
                # Otherwise, use original handler or default
                if original_handler:
                    return await original_handler(request, **path_params)
                else:
                    response_data = self.data_generator.generate_api_response_data(
                        endpoint.path, endpoint.method.value, status_code=200
                    )
                    status_code = 204 if endpoint.method.value == "DELETE" else (201 if endpoint.method.value == "POST" else 200)
                    
                    from fastapi.responses import JSONResponse
                    return JSONResponse(content=response_data, status_code=status_code)
            
            self.add_custom_handler(endpoint.method.value, endpoint.path, error_prone_handler)
        
        self.logger.info(f"Added error simulation ({error_rate*100}% error rate) to all endpoints")